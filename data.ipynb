{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfb84612",
   "metadata": {},
   "source": [
    "## 数据预处理\n",
    "\n",
    "**SFT训练**下载数据格式参考Alpaca数据集格式:\n",
    "\n",
    "```python\n",
    "Dataset({\n",
    "    features: ['instruction', 'input', 'output'],\n",
    "    num_rows: 48818\n",
    "})\n",
    "```\n",
    "\n",
    "然后需要转换成gpt的对话格式，也就是messages：\n",
    "\n",
    "```python\n",
    "{\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        {\"role\": \"assistant\", \"content\": response},\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "最后用tokenizer转换成tokens形式：\n",
    "\n",
    "```python\n",
    "Dataset({\n",
    "    features: ['input_ids', 'labels', 'prompt_len'],\n",
    "    num_rows: 48818\n",
    "})\n",
    "```\n",
    "\n",
    "按步骤运行下面的代码，即可处理数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efb8d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下载数据集(我习惯下载到本地保存)\n",
    "!modelscope download --dataset AI-ModelScope/alpaca-gpt4-data-zh --local_dir /data/lxy/diffusion/data/course/alpaca-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2eaa8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/lxy/miniconda3/envs/diffu/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['instruction', 'input', 'output'],\n",
      "    num_rows: 48818\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# 查看数据集格式\n",
    "from datasets import load_dataset\n",
    "\n",
    "data_path='/data/lxy/diffusion/data/course/alpaca-test'\n",
    "\n",
    "## 代码报错记得删掉数据集里的dataset_infos.json\n",
    "dataset=load_dataset(data_path,split='train')\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e147898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['messages'],\n",
      "    num_rows: 48818\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# 转换成gpt格式\n",
    "def _build_alpaca_prompt(instruction: str, input_text: str | None) -> str:\n",
    "    \"\"\"\n",
    "    Construct a clean text prompt from Alpaca fields.\n",
    "\n",
    "    We intentionally *do not* include Anthropic-style role tags (e.g., \"Human:\", \"Assistant:\")\n",
    "    in the returned prompt, to mirror the return shape of `load_hh_rlhf_dataset` which removes\n",
    "    those tags from the prompt it returns.\n",
    "    \"\"\"\n",
    "    instruction = (instruction or \"\").strip()\n",
    "    input_text = (input_text or \"\").strip()\n",
    "\n",
    "    if input_text:\n",
    "        # Keep instruction and input separated by a blank line for readability.\n",
    "        return f\"{instruction}\\n\\n{input_text}\"\n",
    "    else:\n",
    "        return instruction\n",
    "\n",
    "def map_fn(example):\n",
    "    prompt = _build_alpaca_prompt(\n",
    "        example.get(\"instruction\", \"\"), example.get(\"input\", \"\")\n",
    "    )\n",
    "    response = (example.get(\"output\", \"\") or \"\").strip()\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "            {\"role\": \"assistant\", \"content\": response},\n",
    "        ]\n",
    "    }\n",
    "\n",
    "dataset = dataset.map(\n",
    "        map_fn, remove_columns=dataset.column_names, num_proc=4\n",
    "    )\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97c4082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下载模型文件\n",
    "!modelscope download --model GSAI-ML/LLaDA-8B-Base --local_dir /your/path/of/model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8eff74a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_ids', 'labels', 'prompt_len'],\n",
      "    num_rows: 48818\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 48818/48818 [00:00<00:00, 278937.65 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# 转换成tokens形式\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import Dataset\n",
    "\n",
    "model_path='/data/lxy/diffusion/llada-8b'\n",
    "tokenizer=AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "def default_mdlm_sft_map_fn(row, *, tokenizer, mask_prompt_loss: bool = True) -> dict:\n",
    "    \"\"\"\n",
    "    Build input_ids and labels for SFT.\n",
    "\n",
    "    Args:\n",
    "        row: a dataset row with `messages`\n",
    "        tokenizer: a HF tokenizer\n",
    "        mask_prompt_loss: whether to mask prompt tokens (set their labels to -100)\n",
    "\n",
    "    Returns:\n",
    "        dict with keys: input_ids, labels, and optionally prompt_len\n",
    "    \"\"\"\n",
    "    prompt_response_tokens = tokenizer.apply_chat_template(\n",
    "        row[\"messages\"], tokenize=True, add_generation_prompt=False\n",
    "    )\n",
    "    labels = prompt_response_tokens.copy()\n",
    "\n",
    "    if mask_prompt_loss:\n",
    "        prompt_tokens = tokenizer.apply_chat_template(\n",
    "            row[\"messages\"][:-1], tokenize=True, add_generation_prompt=True\n",
    "        )\n",
    "        labels[: len(prompt_tokens)] = [-100] * len(prompt_tokens)\n",
    "        return {\n",
    "            \"input_ids\": prompt_response_tokens,\n",
    "            \"labels\": labels,\n",
    "            \"prompt_len\": len(prompt_tokens),\n",
    "        }\n",
    "\n",
    "    return {\"input_ids\": prompt_response_tokens, \"labels\": labels}\n",
    "\n",
    "final_datasets = dataset.map(\n",
    "        default_mdlm_sft_map_fn,\n",
    "        fn_kwargs={\"tokenizer\": tokenizer, \"mask_prompt_loss\": True},\n",
    "        num_proc=16,\n",
    "        desc=\"Tokenizing\",\n",
    "        remove_columns=dataset.column_names)\n",
    "final_datasets: Dataset = final_datasets.shuffle(seed=42)\n",
    "print(final_datasets)\n",
    "\n",
    "output_data_path=\"/data/lxy/diffusion/data/course/alpaca-gpt-test\"\n",
    "import os\n",
    "os.makedirs(output_data_path,exist_ok=True)\n",
    "final_datasets.save_to_disk(output_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef01d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'labels', 'prompt_len'],\n",
       "    num_rows: 48818\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看数据集\n",
    "from datasets import load_from_disk\n",
    "\n",
    "ds=load_from_disk(output_data_path)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d2e655",
   "metadata": {},
   "source": [
    "output_data_path对应的数据集就是sft训练需要的数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64f6adf",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
