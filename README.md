# LLaDAæ¨¡å‹é¢„è®­ç»ƒä¸å¾®è°ƒå®æˆ˜

## ğŸ“–ç®€ä»‹

<p align="center">
<img
  src="assets/example2.gif"
  alt="diffusion example">
</p>

åœ¨å‰é¢çš„ç« èŠ‚ä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†å¾ˆå¤šå…³äºè‡ªå›å½’æ¨¡å‹çš„è®­ç»ƒæ–¹æ³•ï¼Œå“ªæ€•æ˜¯å¤šæ¨¡æ€æ¨¡å‹ï¼Œå…¶ä¸­LLMéƒ¨åˆ†ä¹Ÿæ˜¯åŸºäºè‡ªå›å½’æ¨¡å‹çš„ï¼ˆç¬¬å…­ç« ï¼‰ã€‚åœ¨æˆ‘ä»¬çš„è¯¾ç¨‹é‡Œå¹¶æ²¡æœ‰å®Œæ•´çš„å…³äºdiffusionæ¨¡å‹ï¼Œä¹Ÿå°±æ˜¯æ‰©æ•£æ¨¡å‹çš„è®­ç»ƒæ–¹æ³•ã€‚æœ¬æ¬¡æ•™ç¨‹æˆ‘ä»¬å°±æ¥å®ç°diffusionæ¨¡å‹çš„é¢„è®­ç»ƒä»¥åŠå¾®è°ƒï¼Œå…¶ä¸­**å¾®è°ƒä¸ºæ ¸å¿ƒï¼Œé¢„è®­ç»ƒä»…åšå°è¯•ä»¥åŠéªŒè¯ç›¸å…³è®ºæ–‡ä¸­çš„è®ºç‚¹å³å¯ã€‚**

å…¶ä¸­æ‰©æ•£æ¨¡å‹æˆ‘ä»¬é€‰æ‹©LLaDAæ¨¡å‹ï¼Œå¾®è°ƒæ•°æ®é›†è¿˜æ˜¯é‡‡ç”¨ç»å…¸çš„instructæ•°æ®é›†alpacaï¼Œé¢„è®­ç»ƒæ•°æ®é›†ç»è¿‡å¤šæ¬¡è¯•éªŒï¼Œæˆ‘ä»¬é‡‡ç”¨C4æ•°æ®é›†æ¥è¿›è¡Œè®­ç»ƒã€‚

> ä½œè€…ä¿¡æ¯ï¼šæƒ…æ„Ÿæœºå™¨å®éªŒå®¤ç ”ç©¶å‘˜-æé¦¨é›¨  
> é‚®ç®±ï¼šwind.340171@gmail.com

**ğŸ“šèµ„æ–™**

- **æ•°æ®é›†**ï¼š[pretrain](https://www.modelscope.cn/datasets/allenai/c4)ï¼Œ[sft](https://www.modelscope.cn/datasets/AI-ModelScope/alpaca-gpt4-data-zh)
- **æ¨¡å‹**ï¼š[llada-8b](https://www.modelscope.cn/models/GSAI-ML/LLaDA-8B-Base)
- **æ¡†æ¶**ï¼š[dllm](https://github.com/ZHZisZZ/dllm)
- **SwanLab**ï¼š[llada-swanlab](https://swanlab.cn/@LiXinYu/llada-npu-sft/overview)

> æœ¬æ¬¡æ•™ç¨‹lladaå¾®è°ƒçš„æ—¶å€™æ˜¾å­˜å ç”¨$\le35 GB$

**è¯¦ç»†æ•™ç¨‹å’ŒSwanLabè§‚æµ‹ç»“æœé“¾æ¥å¦‚ä¸‹ï¼š**

[![çŸ¥ä¹](https://img.shields.io/static/v1?label=ğŸ“–&message=æ•™ç¨‹&color=blue)](https://zhuanlan.zhihu.com/p/2003124963071266869)
[![SwanLab](https://img.shields.io/static/v1?label=ğŸ“ˆ&message=SwanLab&color=green)](https://swanlab.cn/@LiXinYu/llada-npu-sft/overview)


æœ¬æ¬¡æ•™ç¨‹ä»£ç æºäº[dllm](https://github.com/ZHZisZZ/dllm)ï¼Œé‡Œé¢æœ‰å®Œæ•´çš„lladaæ¨¡å‹é¢„è®­ç»ƒä»¥åŠå¾®è°ƒæ–¹æ³•ï¼Œåœ¨æ­¤æ„Ÿè°¢ä½œè€…å¼€æºlladaè®­ç»ƒæ¡†æ¶ğŸ™ã€‚

<div style="display:flex;justify-content:center;">
  <figure style="text-align:center;margin:0;">
    <img src="./assets/logo.gif" style="width:80%">
  </figure>
</div>



## âš™ï¸ç¯å¢ƒå®‰è£…

- å…‹éš†ä»£ç 

```bash
git clone https://github.com/828Tina/llada-pretrain-sft.git
cd llada-pretrain-sft
```

- å®‰è£…ç¯å¢ƒ

```bash
pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple
```

- ç¡¬ä»¶è¦æ±‚

GPU-32GB $\ge 1$

## ğŸ“Šæ•°æ®å¤„ç†


åœ¨ç®€ä»‹ä¸­æˆ‘ä»¬å¼ºè°ƒï¼ŒSFTæ˜¯æ ¸å¿ƒï¼Œå› æ­¤æˆ‘ä¼šæŒ‰ç…§SFTéœ€è¦çš„æ•°æ®é›†æ ¼å¼æ¥è®²è¿°ï¼Œé¢„è®­ç»ƒå…¶å®éµå¾ªçš„æ˜¯åŒæ ·çš„æ­¥éª¤ï¼Œåªä¸è¿‡é¢„è®­ç»ƒéœ€è¦çš„æ˜¯textæ•°æ®è€Œå·²ã€‚

é¦–å…ˆæˆ‘ä»¬éœ€è¦ä¸‹è½½æ•°æ®é›†ï¼Œæˆ‘å¸Œæœ›ç”¨æœ¬åœ°çš„æ•°æ®é›†æ¥å®Œæˆæœ¬æ¬¡å¾®è°ƒï¼Œå‚è€ƒäº†[datasets](https://huggingface.co/docs/datasets/process#save)å…³äºæ•°æ®ä¿å­˜å’Œä½¿ç”¨çš„ä»£ç ï¼Œè§‰å¾—ä»¥ `Arrow` æ ¼å¼ä¿å­˜åˆ°æœ¬åœ°ç£ç›˜ç„¶åè¯»å–çš„æ–¹å¼æ›´æ–¹ä¾¿ï¼Œ`Arrow` æ˜¯æœªå‹ç¼©çš„ï¼Œå› æ­¤é‡æ–°åŠ è½½é€Ÿåº¦æ›´å¿«ï¼Œéå¸¸é€‚åˆæœ¬åœ°ç£ç›˜ä½¿ç”¨å’Œä¸´æ—¶ç¼“å­˜ã€‚

ä¸Šè¿°è¿‡ç¨‹ä¸»è¦ä½¿ç”¨`save_to_disk`å’Œ`load_from_disk`ä¿å­˜å’ŒåŠ è½½æ•°æ®é›†ï¼Œä¸è¿‡å¦‚æœç£ç›˜ç©ºé—´æœ‰é™ï¼Œå»ºè®®è¿˜æ˜¯ç›´æ¥ç”¨`load_dataset`ã€‚

<div style="background:#e7f8ff;color:#000;padding:12px 16px;border-left:4px solid #20c0ff;">å¦‚æœæƒ³ç›´æ¥é¢„å¤„ç†æ•°æ®é›†çš„å°ä¼™ä¼´ï¼Œå¯ä»¥ç›´æ¥è¿è¡Œ<a href="https://gitee.com/tina_3592874/llada-npu-test/blob/master/data.ipynb"target="_blank" rel="noopener">notebook</a>ä¸­çš„ä»£ç 
</div>

## ğŸ”§è®­ç»ƒå¯åŠ¨

é‚£ä¹ˆæ¥ä¸‹æ¥æˆ‘ä»¬å°±å¼€å§‹è®­ç»ƒå§ï¼Œç”±äºæˆ‘å·²ç»æ•´ç†è¿‡ä»£ç ï¼Œå› æ­¤å¯ä»¥ç›´æ¥è¿è¡Œè„šæœ¬æ–‡ä»¶å®ç°ï¼Œä¸‹é¢ç®€è¦è¯´ä¸‹æ¯ä¸ªæ–‡ä»¶çš„å«ä¹‰å’Œç”¨æ³•ï¼š

```python
â”œâ”€â”€ configs
â”‚   â”œâ”€â”€ llada-100M-pt.yaml          # lladaé¢„è®­ç»ƒè¶…å‚æ•°è®¾ç½®
â”‚   â”œâ”€â”€ llada-8b-sft.yaml           # lladaå¾®è°ƒè¶…å‚æ•°è®¾ç½®
â”‚   â”œâ”€â”€ qwen2.5-100M-pt.yaml        # qwené¢„è®­ç»ƒè¶…å‚æ•°è®¾ç½®
â”‚   â”œâ”€â”€ qwen2.5-7b-alpaca.yaml      # qwenå¾®è°ƒè¶…å‚æ•°è®¾ç½®
â”‚   â”œâ”€â”€ ddp.yaml      # æ•°æ®å¹¶è¡Œåˆ†å¸ƒå¼è®­ç»ƒå‚æ•°è®¾ç½®
â”‚   â”œâ”€â”€ zero2.yaml
â”‚   â””â”€â”€ ...
â”œâ”€â”€ dllm
â”œâ”€â”€ scripts
â”‚   â”œâ”€â”€ train-pt.sh      # lladaé¢„è®­ç»ƒå¯åŠ¨
â”‚   â”œâ”€â”€ train-sft.sh     # lladaå¾®è°ƒè®­ç»ƒå¯åŠ¨
â”‚   â”œâ”€â”€ train-qwen-pt.sh       # qwené¢„è®­ç»ƒå¯åŠ¨
â”‚   â”œâ”€â”€ train-qwen.sh      # qwenå¾®è°ƒè®­ç»ƒå¯åŠ¨
â”‚   â”œâ”€â”€ eval-llada.sh     # lladaæ‰¹é‡æµ‹è¯•å¯åŠ¨
â”‚   â””â”€â”€ eval-qwen.sh      # qwenæ‰¹é‡æµ‹è¯•å¯åŠ¨
â”œâ”€â”€ examples
â”‚   â”œâ”€â”€ llada
â”‚   â”‚   â”œâ”€â”€ pt.py
â”‚   â”‚   â”œâ”€â”€ sft.py
â”‚   â”‚   â”œâ”€â”€ chat.py      # ç»ˆç«¯äº¤äº’å¼å¯¹è¯
â”‚   â”‚   â””â”€â”€ generate.py  # lladaæ¨ç†ä»£ç 
â”‚   â”œâ”€â”€ qwen
â”‚   â”‚   â”œâ”€â”€ pt.py
â”‚   â”‚   â”œâ”€â”€ sft.py
â”‚   â”‚   â”œâ”€â”€ chat.py      # ç»ˆç«¯äº¤äº’å¼å¯¹è¯
â”‚   â”‚   â””â”€â”€ utils.py
```

- `configs`ï¼šåŒ…å«è®­ç»ƒè¶…å‚æ•°è®¾ç½®ã€deepspeedåˆ†å¸ƒå¼è®­ç»ƒå‚æ•°è®¾ç½®ç­‰
- `scripts`ï¼šè®­ç»ƒå¯åŠ¨æ–‡ä»¶ã€evalå¯åŠ¨æ–‡ä»¶ç­‰
- `examples`ï¼šæ ¸å¿ƒå¾®è°ƒã€é¢„è®­ç»ƒè®­ç»ƒä»£ç ç­‰


**é¢„è®­ç»ƒå¯åŠ¨**

- lladaé¢„è®­ç»ƒå¯åŠ¨

```bash
bash scripts/train-pt.sh
```

- qwené¢„è®­ç»ƒå¯åŠ¨(éå¿…éœ€)

```bash
bash scripts/train-qwen-pt.sh
```

**å¾®è°ƒå¯åŠ¨**

- lladaå¾®è°ƒå¯åŠ¨

```bash
bash scripts/train-sft.sh
```

- qwenå¾®è°ƒå¯åŠ¨

```bash
bash scripts/train-qwen.sh
```

**æ¨ç†å¯åŠ¨**

- lladaæ¨¡å‹æ¨ç†

<div style="display:flex;justify-content:center;">
  <figure style="text-align:center;margin:0;">
    <img src="./assets/output.gif" style="width:100%">
  </figure>
</div>


```bash
python examples/llada/chat.py \
    --model_name_or_path "/root/models/LLaDA/output/merge-llada-8b-epoch-3-lr-2e-5" \
    --steps 128 \
    --max_length 128 \
    --block_length 32
```


- qwenæ¨¡å‹æ¨ç†

<div style="display:flex;justify-content:center;">
  <figure style="text-align:center;margin:0;">
    <img src="./assets/output1.gif" style="width:100%">
  </figure>
</div>

```bash
python examples/qwen/chat.py \
        --model_name_or_path /root/models/Qwen/qwen2.5-7b-it \
        --max_new_tokens 256
```